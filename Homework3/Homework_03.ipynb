{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework_03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iVWY-aiMeXP"
      },
      "source": [
        "#Machine Learning Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK7AcB-vMoz2"
      },
      "source": [
        "##Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr1FyRGiMcIV"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I3PqqrJNXZ-"
      },
      "source": [
        "##Read Data from CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2kAMODEON5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84121717-3335-418d-d9ff-c29187158ad8"
      },
      "source": [
        "#read certain data columns from cses4_cut.csv\n",
        "dataset = np.array(pd.read_csv('cses4_cut.csv'))\n",
        "X = dataset[:,1:-1]\n",
        "N = len(X)\n",
        "\n",
        "#read the labels column from csv\n",
        "Y = np.array(pd.read_csv('cses4_cut.csv', usecols=['voted']))\n",
        "print(X.shape)\n",
        "\n",
        "## obtain the labels in the form of 1-hot encoding using sklearn\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse=True)\n",
        "X = encoder.fit_transform(X).toarray() \n",
        "Y = encoder.fit_transform(Y).toarray() \n",
        "print(X)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12451, 31)\n",
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wRkIJRZ7M98"
      },
      "source": [
        "##Feature Selecetion with Chi Square Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DibLfKAe7TYx",
        "outputId": "2e94e709-129c-4b1e-e469-72945b95ecc2"
      },
      "source": [
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "test = SelectKBest(score_func=chi2, k=6)\n",
        "fit = test.fit(X, Y)\n",
        "X =test.fit_transform(X, Y)\n",
        "fit.scores_\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6.51767864e-02, 5.73532102e-02, 4.21599174e-01, 6.39689774e+00,\n",
              "       2.38795629e+01, 3.02513762e+01, 1.49867003e+00, 9.69395369e-01,\n",
              "       5.49438366e+01, 2.87787840e+01, 1.05642183e+00, 6.87697985e+00,\n",
              "       2.00502890e+00, 1.40676884e+00, 1.20390785e+00, 1.42863226e+02,\n",
              "       3.94960557e+00, 1.70247256e-04, 5.67917685e+02, 4.39885676e+00,\n",
              "       1.46628559e+00, 2.48503513e+01, 2.80520492e+01, 1.41584169e+00,\n",
              "       9.69847810e-01, 5.32813032e-02, 4.98083802e-01, 2.76844503e-01,\n",
              "       1.24187797e+01, 1.64447136e-04, 5.22110905e-04, 5.77902797e+01,\n",
              "       5.44274885e+00, 8.18568713e+01, 6.98168475e-01, 3.62377294e-01,\n",
              "       6.43663819e+01, 6.26486419e+00, 8.05909442e+01, 3.91648739e+00,\n",
              "       1.18761989e+00, 6.42684286e+01, 1.15444065e+01, 7.71813835e+01,\n",
              "       3.91648739e+00, 8.49837033e-01, 6.43663819e+01, 3.49221538e+01,\n",
              "       5.30563213e+00, 8.67740859e+00, 5.42072267e+00, 6.28394118e+01,\n",
              "       4.88186054e+02, 8.78558445e+01, 4.72147578e+00, 1.30795021e+01,\n",
              "       1.67483594e+00, 1.05019758e+01, 4.14410136e-02, 7.60361169e+00,\n",
              "       4.88761862e-01, 1.52307843e+00, 1.09767285e+00, 2.05751200e+00,\n",
              "       4.35165265e-01, 2.82857422e+00, 7.43099237e-01, 1.83505448e+00,\n",
              "       4.88761862e-01, 2.57637685e+00, 6.12756895e-02, 3.90048908e+00,\n",
              "       3.09108705e-02, 3.26373949e+00, 1.18402896e-02, 1.08791316e+00,\n",
              "       4.35165265e-01, 1.08791316e+00, 1.96096720e+00, 1.08791316e+00,\n",
              "       1.48724226e+00, 2.10352341e-01, 4.56923528e+00, 2.17582633e-01,\n",
              "       2.17582633e-01, 9.96721455e-01, 8.44029658e-01, 3.26373949e+00,\n",
              "       7.63624924e+00, 1.14926800e+01, 1.41428711e+01, 5.11954013e+00,\n",
              "       5.87473108e+00, 1.18402896e-02, 4.22014829e-01, 1.40676884e+00,\n",
              "       3.27694206e+00, 1.30549580e+00, 4.35165265e+00, 1.08791316e+00,\n",
              "       1.66453582e+00, 2.75258172e+00, 6.28752024e-01, 2.45852419e+00,\n",
              "       1.95824369e+00, 4.35165265e-01, 4.78681792e+00, 1.96201741e+00,\n",
              "       4.35165265e-01, 8.70330530e-01, 1.57345592e+00, 2.94400592e+00,\n",
              "       7.50746515e+00, 1.73296863e+00, 2.15879781e+00, 2.66135891e+00,\n",
              "       4.20704682e-01, 1.46628559e+00, 1.18402896e-02, 5.95688733e-02,\n",
              "       8.70330530e-01, 5.74904295e-01, 4.53374558e+00, 1.66453582e+00,\n",
              "       3.14376012e-01, 2.18763107e-01, 1.00376506e+01, 6.40237412e-02,\n",
              "       6.56856980e-01, 5.92014480e-03, 2.40968889e+00, 5.23761891e-02,\n",
              "       5.37356895e-01, 1.98410330e-02, 6.18217410e-02, 2.15075299e-01,\n",
              "       2.19161378e+00, 4.78472759e-01, 1.27431400e+01, 2.74079876e-01,\n",
              "       1.26913774e+00, 1.61599350e+00, 1.67984156e+01, 3.28428490e-01,\n",
              "       8.70330530e-01, 2.77099374e-01, 1.54554353e-02, 2.17582633e-01,\n",
              "       1.40676884e+00, 2.81805888e+00, 3.65071674e-01, 2.40240861e+00,\n",
              "       1.96096720e+00, 1.09767285e+00, 1.95604190e+00, 1.57345592e+00,\n",
              "       5.75969216e-04, 1.54035912e+00, 2.82857422e+00, 3.93374718e-01,\n",
              "       6.34742562e+00, 7.54346142e-01, 3.49716971e-01, 5.92014480e-03,\n",
              "       9.89491164e-01, 2.77099374e-01, 8.44127494e-03, 1.12078887e-01,\n",
              "       2.40142981e-01, 6.52747898e-01, 2.24497630e-01, 5.77656210e-01,\n",
              "       1.30549580e+00, 4.47145832e+00, 4.40751999e+00, 9.89491164e-01,\n",
              "       4.35165265e-01, 2.84892460e-01, 1.09894234e-01, 1.91678740e+00,\n",
              "       2.20077867e+00, 3.17856570e-06, 1.56188088e-02, 2.68678447e-01,\n",
              "       2.17582633e-01, 5.47168275e-02, 1.47200296e+00, 1.37907668e-01,\n",
              "       1.43671710e-02, 3.20935895e+00, 4.63663058e-02, 8.42971396e+01,\n",
              "       5.28076127e+01, 2.27817917e+01, 1.16175666e+01, 1.30072390e+01,\n",
              "       3.85449631e+00, 2.93257117e+00, 7.77062884e+01, 1.00925274e+02,\n",
              "       4.57441274e+01, 1.40069085e+00, 2.15557910e+00, 3.08429655e+01,\n",
              "       2.10352341e-01, 1.74221343e+00, 1.05019307e+00, 1.99215725e+02,\n",
              "       2.33405367e+01, 4.58895790e+01, 1.20832173e+02, 5.10029363e-01,\n",
              "       7.46422756e-03, 5.47990789e+00, 2.25182953e+02, 1.09026779e+02,\n",
              "       4.07697302e-02, 6.12756895e-02, 1.47200296e+00, 6.38418340e+00,\n",
              "       1.29283807e+01, 6.49083767e+01, 3.14533867e+01, 2.79768048e+00,\n",
              "       2.53827547e+00, 3.28006669e-02, 4.92353709e+01, 8.63840228e-01,\n",
              "       7.80940440e-03, 6.66439672e+01, 1.30549580e+00, 1.38549687e-01,\n",
              "       1.08791316e+00, 2.17582633e-01, 1.47200296e+00, 7.28496150e-04,\n",
              "       5.92014480e-03, 4.35165265e-01, 7.43621132e-01, 2.25716427e+00,\n",
              "       4.88761862e-01, 1.30549580e+00, 1.08791316e+00, 1.38549687e-01,\n",
              "       2.17582633e-01, 2.17582633e-01, 8.63519122e-01, 1.54554353e-02,\n",
              "       2.17582633e+00, 1.57188006e-01, 4.35165265e-01, 4.59595506e+00,\n",
              "       1.52307843e+00, 1.52307843e+00, 1.95824369e+00, 3.69191906e+00,\n",
              "       8.58023711e+00, 5.87473108e+00, 2.80138171e-01, 2.61099159e+00,\n",
              "       1.57188006e-01, 7.43621132e-01, 6.52747898e-01, 6.52747898e-01,\n",
              "       6.52747898e-01, 8.70330530e-01, 6.52747898e-01, 8.70330530e-01,\n",
              "       5.16304241e+00, 2.56562014e+00, 1.95824369e+00, 5.92014480e-03,\n",
              "       2.17582633e-01, 1.38549687e-01, 1.12055268e+00, 2.17582633e-01,\n",
              "       1.08791316e+00, 9.77523724e-01, 1.89589722e+00, 1.48724226e+00,\n",
              "       8.58023711e+00, 2.17582633e+00, 9.17527241e-01, 6.52747898e-01,\n",
              "       3.28006669e-02, 1.95824369e+00, 4.88761862e-01, 3.14376012e-01,\n",
              "       2.83702335e-01, 4.35165265e-01, 2.82857422e+00, 2.61099159e+00,\n",
              "       4.31759561e-01, 1.48724226e+00, 2.75389723e+00, 1.38549687e-01,\n",
              "       1.57188006e-01, 1.30549580e+00, 9.17527241e-01, 6.52747898e-01,\n",
              "       1.38549687e-01, 2.61099159e+00, 1.10530715e+01, 9.77523724e-01,\n",
              "       1.52307843e+00, 3.55208688e-02, 1.48724226e+00, 2.15066198e+00,\n",
              "       4.56923528e+00, 6.12756895e-02, 1.52307843e+00, 2.17582633e-01,\n",
              "       1.38549687e-01, 2.17582633e-01, 1.09767285e+00, 2.68678447e-01,\n",
              "       7.43621132e-01, 1.09433655e-01, 1.30549580e+00, 8.63519122e-01,\n",
              "       3.09108705e-02, 4.35165265e-01, 4.63663058e-02, 1.66841278e+00,\n",
              "       1.22551379e-01, 1.09433655e-01, 1.68825499e-02, 1.83916841e+00,\n",
              "       4.88761862e-01, 1.47200296e+00, 1.30549580e+00, 4.22014829e-01,\n",
              "       2.61099159e+00, 6.52747898e-01, 7.80940440e-03, 2.61099159e+00,\n",
              "       1.95824369e+00, 1.21330490e+00, 6.86553239e+00, 1.66453582e+00,\n",
              "       2.17582633e-01, 1.72906807e+00, 3.48132212e+00, 2.01381354e+00,\n",
              "       1.07290535e+00, 4.80285962e-01, 3.13577970e+00, 7.43621132e-01,\n",
              "       8.70330530e-01, 1.71721981e-01, 3.67010897e+00, 4.13229513e-03,\n",
              "       3.03736212e+00, 1.72593392e+01, 7.07998697e+01, 1.84632425e+01,\n",
              "       5.16304241e+00, 7.77829547e+00, 4.13229513e-03, 3.03736212e+00,\n",
              "       1.64430606e+01, 5.66034594e+01, 6.05702862e+01, 3.09108705e-02,\n",
              "       6.56856980e-01, 3.09199203e+01, 1.16152135e-01, 2.31937363e-01,\n",
              "       1.83505448e+00, 5.05491085e+01, 1.09632851e+01, 2.40918827e+01,\n",
              "       1.14218137e+02, 5.24951500e+00, 1.56188088e-02, 8.85959870e-01,\n",
              "       5.48388269e+01, 7.90914341e+00, 2.65666527e-01, 1.03347989e+00,\n",
              "       2.27434210e+01, 2.10573892e+01, 7.27677108e-02, 4.35164857e+01,\n",
              "       2.81634908e+01, 2.17582633e+00, 1.11962243e+01, 4.07709418e+01,\n",
              "       4.92763531e+00, 1.74451090e+01, 7.01395985e-01, 1.48262456e-01,\n",
              "       2.57357896e+00, 2.75073156e-03, 1.59083873e+00, 3.82057058e-01,\n",
              "       1.09433655e-01, 8.93353613e+00, 1.52307843e+00, 2.10039516e+00,\n",
              "       1.57188006e-01, 6.52747898e-01, 4.35165265e-01, 4.86713429e+00,\n",
              "       4.96745155e+00, 1.00251445e+00, 2.94918040e+02, 1.93041166e+01,\n",
              "       1.88989389e+01, 1.10974669e+01, 1.34450756e+00, 3.07655221e-01,\n",
              "       3.28952748e-02, 1.23435621e-01, 2.86547605e+00, 2.10352341e-01,\n",
              "       2.81353769e+00, 2.81353769e+00, 1.40676884e+00, 2.17582633e-01,\n",
              "       2.17582633e-01, 2.17582633e-01, 2.73099003e+00, 5.75969216e-04,\n",
              "       1.06974042e+02, 3.54728002e+01, 6.00824610e+00, 1.11771495e+00,\n",
              "       4.48207622e-01, 2.45102758e-01, 8.44127494e-03, 5.46198005e-01,\n",
              "       9.19191011e+00, 3.40090018e+00, 2.93257117e+00, 7.53784187e+01,\n",
              "       9.57112790e+01, 3.51253241e+01, 2.61722837e-01, 1.13493403e+00,\n",
              "       2.53962134e+00, 1.57001969e+00, 3.64248075e-03, 1.28013699e+00,\n",
              "       6.66534491e+00, 2.72178162e+00, 1.02228038e+01, 7.10876616e+01,\n",
              "       4.02763316e-02, 1.66171524e-01, 2.56998607e+00, 1.81930183e+02,\n",
              "       3.16749742e+01, 8.78855283e+01, 6.98168475e-01, 2.07387119e+01,\n",
              "       1.99609222e+01, 8.65179694e+00, 2.17582633e+00, 4.13229513e-03,\n",
              "       1.30018245e+00, 5.91540078e+00, 9.76883601e-01, 5.00523835e+00,\n",
              "       2.17582633e-01, 8.70330530e-01, 5.85494530e+00, 2.63094199e+00,\n",
              "       2.17582633e-01, 3.82370723e+00, 4.59595506e+00, 6.18217410e-02,\n",
              "       2.77099374e-01, 5.25346595e+01, 4.03537670e-01, 4.84859336e+00,\n",
              "       6.12756895e-02, 1.20390785e+00, 1.98784576e+00, 1.07192602e+01,\n",
              "       1.54554353e-02, 5.47168275e-02, 6.04678521e+00, 7.85940031e-01,\n",
              "       2.37283245e+00, 9.19191011e+00, 1.40676884e+00, 4.59595506e+00,\n",
              "       1.66841278e+00, 3.83476150e+01, 1.08791316e+00, 2.17582633e-01,\n",
              "       6.52747898e-01, 2.82857422e+00, 2.17582633e-01, 1.40676884e+00,\n",
              "       4.88761862e-01, 6.00755752e-01, 3.16340785e+00, 1.15193843e-03,\n",
              "       1.00251445e+00, 4.56923528e+00, 1.45699230e-03, 1.20241863e+02,\n",
              "       2.17582633e-01, 4.28929826e-01, 1.46628559e+00, 3.93576116e+00,\n",
              "       2.37432121e+01, 4.59595506e+00, 2.73099003e+00, 6.01123682e+01,\n",
              "       6.72437947e-01, 8.19516590e+00, 3.42325697e-01, 1.72393146e+01,\n",
              "       6.71943086e-02, 4.59595506e+00, 1.20839763e+01, 2.46201388e+01,\n",
              "       3.65071674e-01, 1.42515002e+01, 4.35165265e-01, 7.73594582e-03,\n",
              "       3.42432457e+00, 4.35165265e-01, 4.35165265e-01, 2.68265320e+00,\n",
              "       1.55253737e+00, 2.81353769e+00, 1.40676884e+00, 3.18401916e+01,\n",
              "       3.28096511e+00, 1.65010618e+01, 7.06527987e+00, 5.26186311e+00,\n",
              "       1.92704832e+00, 1.69110550e+01, 6.59399604e-01, 4.73769079e-02,\n",
              "       2.60532581e+00, 1.95033396e+00, 9.73331657e+00, 1.36016168e+00,\n",
              "       3.86334852e+00, 8.23924522e+00, 4.33582702e+01, 5.71682924e+00,\n",
              "       2.83232629e+00, 5.98649617e+00, 2.95410380e+00, 2.98577220e+00,\n",
              "       1.84777655e+01, 2.59055737e+00, 4.13407002e+00, 2.00502890e+00,\n",
              "       8.26495730e+00, 7.33142793e+00, 1.57089470e-01, 1.46628559e+00,\n",
              "       6.92748436e-01, 7.28496150e-04, 1.00251445e+00, 1.16152135e-01,\n",
              "       3.67654137e-01, 8.85789710e+00, 2.50261918e+01, 8.55736314e+00,\n",
              "       5.95994126e-01, 6.67365113e+00, 8.34206392e+00, 1.05322234e+00,\n",
              "       5.70289556e+00, 7.78160301e+00, 3.48456406e-01, 1.22235564e+02,\n",
              "       1.00812680e+01, 3.28428490e-01, 2.43889793e+01, 1.46628559e+00,\n",
              "       2.94761140e+00, 1.01039927e+02, 4.59148641e+01, 1.40711242e+00,\n",
              "       2.18924716e-02, 2.66079588e+00, 5.89522281e+00, 1.46014029e+01,\n",
              "       1.18402896e-02, 1.22551379e-01, 4.20193288e+01, 2.35765134e+00,\n",
              "       1.03260848e+01, 1.17504766e+01, 6.11042182e+01, 3.14376012e-01,\n",
              "       1.40676884e+00, 2.17582633e-01, 1.14551774e+01, 1.08345431e+01,\n",
              "       1.29541312e+01, 1.59828032e+00, 1.67150415e+00, 3.14993005e+01,\n",
              "       5.97474157e+01, 2.80935433e+02, 3.60168890e+02, 3.68644835e+02,\n",
              "       3.82051284e+02, 2.14668237e+02, 1.49046387e+02, 8.67574647e+01,\n",
              "       2.64046394e+01, 1.55669068e+01, 3.04012511e+00, 4.35841618e+00,\n",
              "       4.63766114e+00, 1.59867291e+00, 6.32857835e-01, 7.33509310e+00,\n",
              "       5.33164689e-04, 3.75288089e+00, 1.03995244e+00, 3.87802113e-03,\n",
              "       3.29095664e+00, 9.62975035e+00, 4.48501440e+00, 2.96380185e+00,\n",
              "       4.69630325e+00, 9.64934816e+00, 6.57620262e+00, 7.56373061e+00,\n",
              "       1.79315367e+01, 1.46804359e+01, 1.13415173e+01, 7.13492905e+00,\n",
              "       9.04342955e+00, 4.08688816e+00, 2.32786454e+00, 1.62824394e+01,\n",
              "       1.09632851e+01, 5.02699405e+00, 2.04788751e+01, 1.09122057e+01,\n",
              "       3.61532414e+00, 8.18415428e+00, 9.75736630e+00, 7.57321923e+00,\n",
              "       1.13306474e+01, 5.72792761e+00, 1.17096768e+01, 2.29961718e+00,\n",
              "       1.67662725e+01, 1.37230359e+01, 5.30318829e+00, 9.78272455e+00,\n",
              "       5.02433873e+00, 6.92905184e+00, 5.77920073e+00, 4.63264136e+00,\n",
              "       3.82634109e-01, 2.38883013e+00, 3.83184857e+00, 3.10451071e+00,\n",
              "       2.93574074e+00, 6.35713140e-06, 1.23435621e-01, 2.11007414e+00,\n",
              "       3.66181820e+00, 6.88589011e-01, 1.42036985e+00, 1.01832144e+00,\n",
              "       3.90048908e+00, 1.15193843e-03, 8.44029658e-01, 7.43621132e-01,\n",
              "       5.92014480e-03, 4.22014829e-01, 2.80138171e-01, 4.22014829e-01,\n",
              "       1.95504745e+00, 4.35165265e-01, 8.70330530e-01, 2.17582633e-01,\n",
              "       2.17582633e-01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNLN14IB2kJx"
      },
      "source": [
        "##Dimensionality Reduction Using PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqYViCQBegSV"
      },
      "source": [
        "def reduce_dimentions(X):\n",
        "  from sklearn.decomposition import PCA # 1. Choose the model class\n",
        "  model = PCA(n_components=2) # 2. Instantiate the model with hyperparameters\n",
        "  model.fit(X) # 3. Fit to data. Notice y is not specified!\n",
        "  X = model.transform(X)\n",
        "  return X\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewG0nRdYvT9L"
      },
      "source": [
        "##Split Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0ctT4eNSPcC"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test,Y_train, Y_test = train_test_split(X, Y, test_size = 0.2,random_state=1)\n",
        "\n",
        "# reduce dimensionality with PCA for train and test sets\n",
        "X_train_r = reduce_dimentions(X_train)\n",
        "X_test_r= reduce_dimentions(X_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmgwvOj1waBG"
      },
      "source": [
        "##Plot Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "FvR9IAxswYRW",
        "outputId": "1c2aaad0-028f-4884-94c8-ef015af66739"
      },
      "source": [
        "plt.scatter(X_train_r, Y_train)\n",
        "plt.show()\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghdFTb1UykgK"
      },
      "source": [
        "##Gaussian Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxV-1iTNwjiF"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB # 1. choose model class\n",
        "model = GaussianNB() # 2. instantiate model\n",
        "model.fit(X_train, Y_train[:, 1]) # 3. fit model to data\n",
        "Y_model = model.predict(X_test)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chWeFnpCyzko"
      },
      "source": [
        "##GaussianNB Accuracy Score\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb5jhzMny4xd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aa163a3-566e-48c9-f35a-f6d9193ff154"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(Y_test[:,1], Y_model)\n",
        "print(accuracy)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.832597350461662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHeoFg0LzftI"
      },
      "source": [
        "##Confusion Matrix for GaussianNB\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6eoTQB5zmFJ",
        "outputId": "6f8dd7b2-c304-44e5-aaa9-3b84eb243121"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "mat = confusion_matrix(Y_test[:,1], Y_model)\n",
        "print(\"The Confusion Matrix for GaussianNB:\\n\", mat)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Confusion Matrix for GaussianNB:\n",
            " [[ 103  361]\n",
            " [  56 1971]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wlkFczbIc-n"
      },
      "source": [
        "##KN Neighbors Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zx5hX_ZzKZ_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "1cf04dc6-c82a-430f-8cbb-e3c20cae3f53"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def tune_KNN(N, k_values):\n",
        "  accuracies = []\n",
        "  for k in k_values:\n",
        "    # instantiate kNN with given neighbor size k\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    # run cross validation for a given kNN setup\n",
        "    # I have setup n_jobs=-1 to use all cpus in my env.\n",
        "    scores = cross_val_score(knn, X_train_r, Y_train, cv=10, scoring='accuracy', n_jobs=-1)\n",
        "    accuracies.append(scores.mean())\n",
        "  return accuracies\n",
        "\n",
        "\n",
        "k_values = [i for i in range(1, 1000)]\n",
        "accuracies = tune_KNN(N, k_values)\n",
        "print(accuracies)\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors= np.argmax(accuracies))\n",
        "model.fit(X_train_r, Y_train)\n",
        "y_model = model.predict(X_test_r)\n",
        "Score = accuracy_score(Y_test, y_model)\n",
        "print(Score)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-50f66e5b6e15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mk_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtune_KNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-50f66e5b6e15>\u001b[0m in \u001b[0;36mtune_KNN\u001b[0;34m(N, k_values)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# run cross validation for a given kNN setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# I have setup n_jobs=-1 to use all cpus in my env.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 236\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbQ4NVknK0J8"
      },
      "source": [
        "plt.plot(k_values, accuracies)\n",
        "plt.xlabel('Value of K for KNN')\n",
        "plt.ylabel('Cross-Validated Accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAeLFKnWDJzW"
      },
      "source": [
        "##LogisticRegression Optimization by GridSearchCV\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pnmTls2Smpf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a2ef5b3-d4fe-48ea-b623-aab472898d1f"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "param_grid = [\n",
        "              {'penalty' : ['l1','l2', 'elasticnet'],\n",
        "               'C' : np.logspace(-8,8,20),\n",
        "               'solver' : ['lbfgs', 'newton-cg', 'liblinear', 'sag', 'saga'],\n",
        "               'max_iter' : [100,1000, 2500, 5000]\n",
        "              }]\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "clf = GridSearchCV(model, param_grid=param_grid, cv = 3, verbose=True, n_jobs=-1)\n",
        "clf_best = clf.fit(X_train, Y_train[:,1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1200 candidates, totalling 3600 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:    5.1s\n",
            "[Parallel(n_jobs=-1)]: Done 2556 tasks      | elapsed:   20.3s\n",
            "[Parallel(n_jobs=-1)]: Done 3600 out of 3600 | elapsed:   29.3s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNPXiGErNnZA",
        "outputId": "9217cd63-acc9-499d-e1e0-b7a1ae0ced6b"
      },
      "source": [
        "clf_best.best_estimator_"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.3792690190732246, class_weight=None, dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l1',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmOTmTVoPDd4"
      },
      "source": [
        "best_score = clf_best.score(X_train, Y_train[:,1])\n",
        "best_param = clf_best.best_params_"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO2aamW2l8NI"
      },
      "source": [
        "##Use of LogisticRegression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvsigrnsPjnN",
        "outputId": "d84c85db-382a-426f-b443-a8b6d819d60b"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(random_state=0, C=best_param.get('C'), penalty=best_param.get('penalty'), solver=best_param.get('solver'), max_iter=best_param.get('max_iter'))\n",
        "model.fit(X_train, Y_train[:,1])\n",
        "Y_model = model.predict(X_test) \n",
        "accuracy = accuracy_score(Y_test[:,1], Y_model)\n",
        "print(accuracy)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8334002408671216\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}